
            OVERVIEW OF THE PROLOG LANGUAGE

     The first thing you must understand about Prolog is that it is an
interpreted language, as opposed to a compiled language like C.  In
the case of a compiled language, the compiler translates the readable
ASCII file containing a program into an object file which can be
executed directly by a computer.  After this object file has been
created, the original program, and the compiler itself, can be set
aside.

     This is not possible with an interpreted language like Prolog,
however.  In this case, the interpreter must be running on the
computer at the time of program execution, because it produces no
secondary object file.  Instead, it interprets the meaning of the
program one step at a time.

     To understand how Prolog interprets a program, go back to the
simple philosopher database mentioned in the article and ask yourself
how you were able to deduce that Plato is wise.  A little
introspection will reveal the following steps:

         1. Find a clause whose head matches the predicate you
    are trying to prove.  This clause can be a rule or a fact,
    because a fact is considered to be a head without a body.

         2. If the matched clause is a fact, the goal has been
    proven, so go on to prove the remaining goals. (If there are
    no goals remaining, the process halts successfully.)

         3. If the matched clause was a rule, it is now known
    that in order to prove the head, the predicate(s) of the body
    must be proved.  This is simply the procedural interpretation
    of a rule that was mentioned earlier. So add the predicate(s)
    in the body of the rule to the list of goals that need to be
    proved, and continue.

     If a person were to apply this method to the philosopher
database, the reasoning might be as follows:

         The first clause matches up with wise(Plato) if I
    replace the x with Plato, so that tells me that in order to
    determine whether Plato is wise, I need first to determine if
    he is Greek, and then determine whether he is a philosopher.
    The first assertion can be proven with clause number two,
    which tells me that Plato is, in fact, Greek.  Having proven
    my first goal, it remains only to prove that Plato is a
    philosopher.  The second clause doesn't help me here, but the
    third matches nicely, and proves the second and last goal.
    Since all the goals have been proven, I'm done.

     This, in essence, is just how Prolog would solve the problem: it
chooses a goal from the current list (always the left-most one), and
searches the database for clauses whose heads match the goal (always
choosing the first clause that if finds if more than one clause
matches).  As more goals are generated by the matching process, they
are added to the list and solved one at  time.  If Prolog ever finds
that it simply cannot prove a goal, it gives up and reports failure;
if it can prove all the goals, it reports success.

     Unfortunately, things don't usually work out this nicely.
Consider the following expanded database:

     wise(x) :- student-of-Socrates(x)
     wise(x) :- Greek(x), philosopher(x)
     Greek(Plato)
     philosopher(Plato).

     Note the addition of the rule "wise(x) :-
student-of-Socrates(x)."  If Prolog is presented with this database,
it will, as before, first match the first rule with its initial goal
of wise(Plato), and then try to prove the newly-generated goal
"student-of-Socrates(Plato)."  But at this point, Prolog runs into a
dead end: it finds that the goal cannot be proven.  (Notice,
incidentally, that there is nothing in the database that says that
Plato was not a student of Socrates.  [In fact, he was.]  Prolog --
like quite a few people -- assumes that it knows everything there is
to know about a subject.  If a fact is not in its database, it is
assumed to be false.)  At this point, Prolog backs up.  It retracts
any variable assignments that it has made in this unification attempt
(here, assigning "Plato" to x) and then tries to find another
applicable rule.  It does find a rule that matches, so it can
continue.  This process of undoing part of the proof and backing up to
try new routes is known as backtracking, and it is an integral part of
Prolog's algorithm.

     Up till now, the process of finding a suitable clause whose head
is the same as the goal being proven has been informally referred to
as "matching."  This matching is in fact the heart of the
interpretation process, and is the only way that variables can take on
a value in pure logic programming. Its real name is "unification."
The unification algorithm that Prolog uses is outlined in the text
file on disk FIGURE1.  It simply makes explicit our intuitive
understanding of what it means to match two clauses.

     You'll notice that "binding" variables is an important part of
the unification algorithm.  Bindings in Prolog, and variables in
general, deserve some comment, because they are unfamiliar concepts to
one used to conventional languages.  First of all, it's possible to
borrow a term from conventional languages and speak of the "scope" of
Prolog variables -- that is, the extent to which a given variable name
has meaning.  In a language like C, the variables declared in a
function heading are known as "formal parameters," and they are really
only placeholders that take on values only when the function is
invoked.  They are completely distinct from formal parameters of other
functions, even if their names are identical to these other
variables.

     What has been said here of C is also true of Prolog: a
predicate's arguments are completely local to that clause only.  So,
for example, consider the pair of clauses

     1. wise(x) :- student-of-Socrates(x)
     2. wise(x) :- Greek(x), Philosopher(x).

As you'd expect, both x's in the first clause are instances of the
same variable; when the first is bound to something, so is the second.
However, the x's in the first clause have no special relationship to
the x's in the second.  Binding the first set of x's to something has
no effect on the x's in the second clause.

     There's nothing new in any of this; what is new is the concept of
binding.  It must not be thought that a binding in Prolog is the same
as an assignment in a conventional language.  Consider what happens
when a C programmer writes

     x = expression.

First of all, the compiler has set aside in memory a space to hold the
value of x.  Unless the programmer explicitly tells the compiler to
initialize this space, its contents at the beginning of the program's
execution are completely unpredictable; all that is known is that at
all times a variable must have some value.  When the above line of
code is executed, the value of "expression" is moved into the space
reserved for x (and "expression," like all conventional variables,
always holds a value).  So x takes on a (probably) new value -- a
value that may very well be written over milliseconds later, because
it is understood that a variable is only a holding place, and its
value may change any number of times during a program's execution.
This is one of the things that makes debugging a conventional program
so hard.  Even if you've verified that a variable has the correct
value at some point in the program's execution, this is no assurance
that the variable will hold the correct value at the next line of
code.

     A Prolog binding, on the other hand, is a very different thing.
First of all, a Prolog variable is not set to another variable, but is
bound to it.  An example will illustrate the difference.  According to
the unification algorithm, unifying

     wise(y)

with

     wise(x)

will produce as a side effect a binding of x to y.  If y currently has
the value "Socrates," x will take on this value, too, as you'd expect.
But x and y are now bound together, and are in a sense the same
variable; if y is bound to a different value, x will be bound to that
same value.  And there's more.  A Prolog variable may very well have
no value, in which case it is said to be unbound.  This is not to say
that it has a value of 0; it means that the variable simply has no
value at all.  Two Prolog variables can be bound to each other even if
neither of them currently has a value.

     Notice also that a Prolog variable is not a temporary holding
place which will take on an indefinite number of values.  A Prolog
variable is either bound or it isn't, and that's that.  Once it is
bound to something in the course of a unification, it will stay that
way, and never be reset.  (Keep in mind that "variable" in this
context refers to a particular variable in a particular unification of
a clause.  The Prolog identifier x may take on a hundred different
values in the course of a hundred different unifications, but as
explained above, the x in one unification is entirely different from
the x in another.)

THE INTERPRETING ALGORITHM IN GREATER DETAIL

     Having examined unification and variable bindings, it is time to
take a closer look at just how Prolog solves problems.  The algorithm
is best described in terms of a search tree. Such a tree is
illustrated in Figure 2.  If you've never encountered a search tree,
you'll need a bit of terminology.  A tree consists of a number of
nodes and lines which express the relationships between those nodes.
Nodes which have lines connecting them with nodes below them are
called parent nodes, and the lower nodes are known as its children.
Finally, unlike its real-life counterpart, a search tree has its root
node (the node with no parent) at the top, and its leaf nodes (nodes
with no children) at the bottom.

     As you'd expect, the principal operation to be performed on a
search tree is to search it, starting at the root, for a node that has
some desired property. One algorithm for searching a tree is a
depth-first search, so called because it requires that you go as far
down in the tree as you can until you reach a leaf node, and then back
up and move to the right, halting when either the desired node is
located or the tree is exhausted.  The algorithm is specified in
Figure 3.  Notice the use of backtracking, which in this context means
moving back up the tree to a previous juncture and making a new
choice.

     In examining the algorithm, you'll notice that it is recursive;
that is, it calls itself.  This makes sense, because a search tree is
inherently recursive.  A tree consists of one or more subtrees, which
consist of one or more subtrees, which consist... and so on until the
leaf nodes are reached.  Because Prolog is really just a tree-search
algorithm, it is thoroughly recursive, as both the unification and
interpretation algorithms demonstrate.

     Neither the concept of a search tree nor the depth-first search
algorithm is unique to Prolog; both have numerous applications in
computer science.  It remains now to illustrate how Prolog uses these
concepts.  As mentioned above, the Prolog problem-solving method is
simply a depth-first search of a particular tree, namely the tree
defined by the database in use.  The tree is created as follows: the
root node is the collection of the initial goal(s).  Its children
(and, in general, the children of any node) are the nodes created by
replacing the left-most goal with the body of the first clause with
which it unifies.  (Remember that a fact is really a rule with NIL for
a body, so a goal that unifies with a fact simply disappears.)  In
other words, each node in the tree holds the goals which remain to be
solved at that point in the proof process.  A sample database, along
with the search tree it creates, are illustrated in Figure 4.
Incidentally, the entire search tree for a large database could well
be unimaginably huge,  but don't worry.  It's not necessary to create
the whole tree and store it in memory before searching it.  The tree
as a whole is generally only an abstraction; individual nodes are
created only as the search leads through them.

                       FIGURE 2 - A SEARCH TREE

            A
           / \
          B   C
         / \   \
        D   E   F
       / \   \   \
      G   H   I   X




             FIGURE 3 - THE DEPTH-FIRST SEARCH ALGORITHM

    Inputs: a tree and a goal node
    Output: success or failure

    it is assumed that a function "child" exists to generate in
left-to-right order all the children of a node, and the function
"parent" exists to return the parent of a node

    DFS(tree,goal)

    if root node of tree = goal
         return SUCCESS
    else {try all the subtrees}
    repeat
         if subtree = child(tree)
              if DFS(subtree,goal) = SUCCESS
                   return SUCCESS
    until subtree = NIL

    {we now know that this branch of the tree doesn't contain the
goal}
    return FAILURE

        FIGURE 4 - SAMPLE DATABASE AND RESULTING SEARCH TREE

GOAL :- A,B
A :- C
C :- D
A :- E
E :- F
F
B :- G
B :- H
H

         A,B
        /   \
      C,B   E,B
      /       \
    D,B       F,B
                \
                 B
                / \
               G   H
                   |

